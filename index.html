<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>PhoenixVA ‚Äî Voice + Text Portal (Mobile-friendly)</title>
    <style>
      body { font-family: system-ui, Arial, sans-serif; margin: 40px; }
      h1 { margin-top: 0; }
      #row { margin: 8px 0; display:flex; align-items:center; gap:10px; flex-wrap:wrap; }
      input[type="text"] { width: 360px; max-width: 100%; padding: 8px; font-size: 16px; }
      button { padding: 10px 16px; font-size: 16px; margin-right: 6px; }
      #output { margin-top: 16px; padding: 12px; border: 1px solid #ddd; min-height: 90px; white-space: pre-wrap; }
      #status { color:#555; }
      #diag { margin-top: 8px; font-size: 12px; color:#666; white-space: pre-wrap; max-height: 180px; overflow:auto; }
      /* Prominent CHAT toggle (black bg, scarlet text) */
      .rt-container{ display:flex; align-items:center; gap:12px; padding:8px 12px; border:2px solid black; border-radius:16px; background:black; }
      .rt-label{ font-weight:700; font-size:18px; color:#b3132c; letter-spacing:.3px; }
      .rt-toggle{ position:relative; width:76px; height:40px; border-radius:999px; background:#222; border:2px solid #b3132c; cursor:pointer; display:inline-flex; align-items:center; padding:2px; transition:background .2s ease; }
      .rt-toggle[aria-checked="true"]{ background:#330000; }
      .rt-thumb{ width:34px; height:34px; border-radius:999px; background:#b3132c; transform: translateX(0); transition: transform .2s ease; }
      .rt-toggle[aria-checked="true"] .rt-thumb{ transform: translateX(36px); }
      .rt-note{ font-size:12px; color:#b3132c; margin-left:4px; }
      .rt-badge{ font-size:12px; padding:4px 8px; border-radius:999px; background:black; color:#b3132c; border:1px solid #b3132c; }
      .rt-badge.off{ background:#111; color:#666; border-color:#333; }
    </style>
  </head>
  <body>
    <h1>PhoenixVA ‚Äî Voice + Text Portal</h1>

    <div id="row">
      <button id="pressBtn">üéôÔ∏è Hold to Talk</button>

      <div class="rt-container" role="group" aria-label="CHAT toggle">
        <span class="rt-label">CHAT</span>
        <div id="rtToggle" class="rt-toggle" role="switch" aria-checked="false" tabindex="0" aria-label="Toggle CHAT mode">
          <div class="rt-thumb"></div>
        </div>
        <span id="rtBadge" class="rt-badge off">OFF</span>
        <span class="rt-note">Realtime loop active when ON</span>
      </div>

      <span id="status"></span>
    </div>

    <div id="row">
      <input id="textInput" type="text" placeholder="Type your message‚Ä¶" />
      <button id="sendBtn">Send</button>
    </div>

    <div id="output">Ready.</div>
    <div id="diag"></div>

    <script>
      const pressBtn  = document.getElementById('pressBtn');
      const sendBtn   = document.getElementById('sendBtn');
      const textInput = document.getElementById('textInput');
      const output    = document.getElementById('output');
      const statusEl  = document.getElementById('status');
      const diag      = document.getElementById('diag');

      const rtToggle = document.getElementById('rtToggle');
      const rtBadge  = document.getElementById('rtBadge');
      let realtimeActive = false;

      // MIME candidates (auto detect)
      const CANDIDATE_MIMES = [
        'audio/webm;codecs=opus','audio/webm','audio/ogg;codecs=opus','audio/mp4;codecs=mp4a','audio/mpeg'
      ];
      function detectSupportedMime(){
        try{
          if(!(window.MediaRecorder && MediaRecorder.isTypeSupported)) return null;
          return CANDIDATE_MIMES.find(t => MediaRecorder.isTypeSupported(t)) || null;
        }catch{ return null; }
      }
      let chosenMime = detectSupportedMime() || 'audio/webm';
      function extFromMime(m){
        if(!m) return 'webm';
        if(m.includes('mp4')) return 'mp4';
        if(m.includes('ogg')) return 'ogg';
        if(m.includes('mpeg')) return 'mp3';
        return 'webm';
      }
      const chosenExt = extFromMime(chosenMime);

      function log(s){ diag.textContent += `\n${s}`; diag.scrollTop = diag.scrollHeight; }

      async function speak(text){
        try{
          const r = await fetch('/api/speak',{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({ text, voice:'alloy' }) });
          if(!r.ok) return;
          const buf = await r.arrayBuffer();
          const url = URL.createObjectURL(new Blob([buf],{ type:'audio/mpeg' }));
          await new Promise(res=>{
            const a = new Audio(url);
            a.onended = res; a.onerror = res;
            a.play().catch(res);
          });
        }catch(e){ log(`TTS error: ${String(e)}`); }
      }

      function blobToDataUrl(blob){
        return new Promise((resolve,reject)=>{
          const fr = new FileReader();
          fr.onload = ()=>resolve(fr.result);
          fr.onerror = reject;
          fr.readAsDataURL(blob);
        });
      }

      // ===== Text path =====
      async function sendMessage(msg){
        output.textContent = 'Thinking‚Ä¶';
        const m = msg.trim();
        const isSearch = /^(\s*search:|\s*web:)/i.test(m);
        if(isSearch){
          const q = m.replace(/^(\s*search:|\s*web:)/i,'').trim();
          if(!q){ output.textContent='Please provide a search query.'; return; }
          try{
            const r = await fetch('/api/search',{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({ q }) });
            const data = await r.json();
            if(!r.ok || data.error){ output.textContent='Search error.'; log(`Search error: ${(data && (data.error||data.detail))||r.statusText}`); return; }
            const lines = (data.results||[]).map((it,i)=>`${i+1}. ${it.title}\n${it.link}\n${it.snippet}`).join('\n\n');
            output.textContent = lines || 'No results.';
            const top = (data.results||[])[0]; if(top){ await speak(`Top result: ${top.title}. ${top.snippet}`); }
            return;
          }catch(e){ output.textContent='Search request failed.'; log(`Search fetch error: ${String(e)}`); return; }
        }
        try{
          const r = await fetch('/api/chat',{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({ message: m }) });
          const data = await r.json();
          const reply = data.reply || data.error || '(no reply)';
          output.textContent = reply;
          await speak(reply);
        }catch{ output.textContent='Network error'; }
      }

      sendBtn.onclick = ()=>{
        const msg = textInput.value.trim();
        if(!msg) return;
        textInput.value = '';
        sendMessage(msg);
      };
      textInput.addEventListener('keydown', e=>{ if(e.key==='Enter') sendBtn.click(); });

      // ===== Press-and-hold single-shot (unchanged logic) =====
      let mediaRecorder, audioChunks=[];
      async function startRecording(){
        if(!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia){ output.textContent='This browser does not support microphone capture.'; return; }
        const stream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true, channelCount:1 } });
        try{ mediaRecorder = new MediaRecorder(stream, { mimeType: chosenMime }); } catch{ mediaRecorder = new MediaRecorder(stream); }
        audioChunks = [];
        mediaRecorder.ondataavailable = e=> e.data && e.data.size && audioChunks.push(e.data);
        mediaRecorder.onstop = onStoppedSingleShot;
        mediaRecorder.start();
        log(`Recorder MIME (single-shot): ${chosenMime} | ext: .${chosenExt}`);
      }
      async function onStoppedSingleShot(){
        const blob = new Blob(audioChunks,{ type: chosenMime });
        log(`Blob size: ${blob.size} bytes; type: ${blob.type}`);
        if(!blob.size){ statusEl.textContent='No audio captured'; output.textContent='No audio captured.'; return; }
        statusEl.textContent='Transcribing‚Ä¶'; output.textContent='Transcribing‚Ä¶';
        try{
          const dataUrl = await blobToDataUrl(blob);
          const tr = await fetch('/api/transcribe',{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({ audio: dataUrl }) });
          const tdata = await tr.json();
          if(!tr.ok || tdata.error){ output.textContent='Transcription error.'; log(`Transcribe error: ${tdata.error || tr.statusText}${tdata.detail? ' | '+tdata.detail:''}`); statusEl.textContent='Error'; return; }
          const text = (tdata.text||'').trim();
          if(!text){ statusEl.textContent='No speech detected'; output.textContent='No speech detected.'; return; }
          if(/^(\s*search:|\s*web:)/i.test(text)){ statusEl.textContent='Searching‚Ä¶'; await sendMessage(text); statusEl.textContent='Ready'; return; }
          statusEl.textContent='Asking‚Ä¶'; output.textContent = 'You said: '+text+'\nThinking‚Ä¶';
          const cr = await fetch('/api/chat',{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({ message: text }) });
          const cdata = await cr.json(); const reply = cdata.reply || '(no reply)';
          output.textContent = 'You said: '+text+'\nAssistant: '+reply; statusEl.textContent='Ready'; await speak(reply);
        }catch(e){ statusEl.textContent='Error'; output.textContent='Error during transcription or chat.'; log(`Client error: ${String(e)}`); }
      }
      function stopRecording(){ if(mediaRecorder && mediaRecorder.state!=='inactive') mediaRecorder.stop(); }
      pressBtn.onmousedown = async ()=>{ statusEl.textContent = realtimeActive ? 'Recording‚Ä¶ (press) ‚Äî CHAT ON' : 'Recording‚Ä¶ (hold)'; await startRecording(); };
      pressBtn.onmouseup   = ()=>{ statusEl.textContent='Processing‚Ä¶'; stopRecording(); };
      pressBtn.onmouseleave= ()=>{ if(mediaRecorder && mediaRecorder.state==='recording'){ statusEl.textContent='Processing‚Ä¶'; stopRecording(); } };
      pressBtn.ontouchstart= async (e)=>{ e.preventDefault(); statusEl.textContent = realtimeActive ? 'Recording‚Ä¶ (press) ‚Äî CHAT ON' : 'Recording‚Ä¶ (hold)'; await startRecording(); };
      pressBtn.ontouchend  = (e)=>{ e.preventDefault(); statusEl.textContent='Processing‚Ä¶'; stopRecording(); };

      // ===== Realtime loop with coalesced pending chunks =====
      let rtStream=null, rtRecorder=null, rtBufferText='', rtTranscribing=false, rtInterval=null, rtTick=0;
      let inactivityTimer=null;
      let rtPendingBlob=null;           // NEW: holds latest unprocessed chunk
      const CHUNK_MS = 500;             // faster ticks; coalescing prevents backlog
      const INACTIVITY_MS = 1300;       // finalize if no new text for ~1.3s
      const END_PUNCT_RE = /[.!?‚Ä¶]"?$/;

      function mergePartial(prev, incoming){
        if(!incoming) return prev;
        if(incoming.startsWith(prev)) return incoming;          // full replacement pattern
        if(prev && incoming && prev.endsWith(incoming)) return prev; // duplicate tail
        return prev ? (prev + ' ' + incoming) : incoming;       // conservative append
      }

      function scheduleFinalize(){
        if(inactivityTimer) clearTimeout(inactivityTimer);
        inactivityTimer = setTimeout(()=> finalizeUtterance(), INACTIVITY_MS);
      }

      function micConstraints(){
        return { echoCancellation:true, noiseSuppression:true, autoGainControl:true, channelCount:1 };
      }

      async function startRealtime(){
        if(rtRecorder) return;
        statusEl.textContent='CHAT mode: listening‚Ä¶';
        rtBufferText=''; rtTick=0; rtPendingBlob=null;

        try{
          rtStream = await navigator.mediaDevices.getUserMedia({ audio: micConstraints() });
          try{ rtRecorder = new MediaRecorder(rtStream, { mimeType: chosenMime }); }
          catch{ rtRecorder = new MediaRecorder(rtStream); }
          rtRecorder.ondataavailable = onRtChunk;
          rtRecorder.onstop = ()=> log('[CHAT] recorder stopped');
          rtRecorder.start(); // we drive requestData
          rtInterval = setInterval(()=> {
            rtTick++;
            try{ if(rtRecorder && rtRecorder.state==='recording') rtRecorder.requestData(); }catch(e){ log(`[CHAT] requestData error: ${String(e)}`); }
            if(rtTick%3===0) log(`[CHAT] tick ${rtTick}`);
          }, CHUNK_MS);
          log(`[CHAT] Realtime started (${chosenMime}); forced chunks every ${CHUNK_MS}ms`);
        }catch(err){
          log(`[CHAT] Failed to start: ${String(err)}`);
          statusEl.textContent='CHAT error: mic unavailable';
          stopRealtime();
        }
      }

      async function stopRealtime(){
        try{ if(rtInterval) clearInterval(rtInterval); }catch{}
        rtInterval=null;
        try{ if(rtRecorder && rtRecorder.state!=='inactive') rtRecorder.stop(); }catch{}
        rtRecorder=null;
        try{ if(rtStream) rtStream.getTracks().forEach(t=>t.stop()); }catch{}
        rtStream=null;
        if(inactivityTimer){ clearTimeout(inactivityTimer); inactivityTimer=null; }
        statusEl.textContent='CHAT OFF. Press-and-hold active.';
      }

      async function onRtChunk(ev){
        if(!ev || !ev.data) return;
        const size = ev.data.size || 0;
        log(`[CHAT] chunk: ${size} bytes`);

        if(size === 0){
          // No new audio in this tick; do nothing ‚Äî debounce will handle finalize.
          return;
        }

        // If a transcribe request is in flight, keep only the latest pending chunk
        if(rtTranscribing){
          rtPendingBlob = ev.data;  // replace any older pending with the newest chunk
          return;
        }

        // Process this chunk now
        await processChunk(ev.data);
        // After finishing, if a newer chunk arrived meanwhile, process it immediately
        while(rtPendingBlob){
          const next = rtPendingBlob;
          rtPendingBlob = null;     // clear before processing to allow coalescing
          await processChunk(next);
        }
      }

      async function processChunk(blob){
        if(rtTranscribing) return; // safety
        rtTranscribing = true;
        try{
          const dataUrl = await blobToDataUrl(blob);
          const tr = await fetch('/api/transcribe',{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({ audio: dataUrl }) });
          const tdata = await tr.json();
          const chunkText = (tdata && tdata.text || '').trim();

          if(chunkText){
            rtBufferText = mergePartial(rtBufferText, chunkText);
            output.textContent = `You (live): ${rtBufferText}`;

            if(END_PUNCT_RE.test(rtBufferText.trim())){
              if(inactivityTimer){ clearTimeout(inactivityTimer); inactivityTimer=null; }
              await finalizeUtterance();
              return;
            }
            scheduleFinalize();
          }
        }catch(err){
          log(`[CHAT] transcribe error: ${String(err)}`);
        }finally{
          rtTranscribing = false;
        }
      }

      async function finalizeUtterance(){
        if(inactivityTimer){ clearTimeout(inactivityTimer); inactivityTimer=null; }
        const utterance = rtBufferText.trim();
        rtBufferText = '';
        if(!utterance) return;

        await pauseRealtimeDuring(async ()=>{
          statusEl.textContent='Thinking‚Ä¶';
          output.textContent = `You: ${utterance}\nThinking‚Ä¶`;

          if(/^(\s*search:|\s*web:)/i.test(utterance)){
            await sendMessage(utterance);
            statusEl.textContent='CHAT mode: listening‚Ä¶';
            return;
          }

          try{
            const cr = await fetch('/api/chat',{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({ message: utterance }) });
            const cdata = await cr.json();
            const reply = cdata.reply || '(no reply)';
            output.textContent = `You: ${utterance}\nAssistant: ${reply}`;
            await speak(reply);
          }catch(err){
            log(`[CHAT] chat error: ${String(err)}`);
            output.textContent = `You: ${utterance}\nAssistant: (error)`;
          }finally{
            statusEl.textContent='CHAT mode: listening‚Ä¶';
          }
        });
      }

      async function pauseRealtimeDuring(fn){
        const wasActive = !!rtRecorder;
        if(wasActive){ try{ rtRecorder.stop(); }catch{} rtRecorder=null; }
        try{ await fn(); }
        finally{ if(realtimeActive){ await startRealtime(); } }
      }

      function setRealtimeActive(on){
        realtimeActive = !!on;
        rtToggle.setAttribute('aria-checked', realtimeActive ? 'true':'false');
        rtBadge.textContent = realtimeActive ? 'ON' : 'OFF';
        rtBadge.classList.toggle('off', !realtimeActive);
        if(realtimeActive){ statusEl.textContent='CHAT mode: initializing‚Ä¶'; startRealtime(); }
        else { stopRealtime(); }
      }
      function toggleRealtime(){
        const next = !(rtToggle.getAttribute('aria-checked')==='true');
        setRealtimeActive(next);
      }
      rtToggle.addEventListener('click', toggleRealtime);
      rtToggle.addEventListener('keydown', e=>{ if(e.key===' '||e.key==='Enter'){ e.preventDefault(); toggleRealtime(); } });

      document.addEventListener('visibilitychange', ()=>{
        if(document.visibilityState==='visible' && realtimeActive && !rtRecorder){
          log('[CHAT] page visible ‚Äî restarting realtime');
          startRealtime();
        }
      });

      setRealtimeActive(false);
    </script>
  </body>
</html>
