<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>PhoenixVA ‚Äî Voice + Text Portal (Mobile-friendly)</title>
    <style>
      body { font-family: system-ui, Arial, sans-serif; margin: 40px; }
      h1 { margin-top: 0; }
      #row { margin: 8px 0; display:flex; align-items:center; gap:10px; flex-wrap:wrap; }
      input[type="text"] { width: 360px; max-width: 100%; padding: 8px; font-size: 16px; }
      button { padding: 10px 16px; font-size: 16px; margin-right: 6px; }
      #output { margin-top: 16px; padding: 12px; border: 1px solid #ddd; min-height: 90px; white-space: pre-wrap; }
      #status { color:#555; }
      #diag { margin-top: 8px; font-size: 12px; color:#666; white-space: pre-wrap; }

      /* Prominent CHAT toggle (black bg, scarlet text) */
      .rt-container{
        display:flex; align-items:center; gap:12px; padding:8px 12px;
        border:2px solid black; border-radius:16px; background:black;
      }
      .rt-label{
        font-weight:700; font-size:18px; color:#b3132c; letter-spacing:.3px;
      }
      .rt-toggle{
        position:relative; width:76px; height:40px; border-radius:999px;
        background:#222; border:2px solid #b3132c; cursor:pointer;
        display:inline-flex; align-items:center; padding:2px; transition:background .2s ease;
      }
      .rt-toggle[aria-checked="true"]{ background:#330000; }
      .rt-thumb{
        width:34px; height:34px; border-radius:999px; background:#b3132c;
        transform: translateX(0); transition: transform .2s ease;
      }
      .rt-toggle[aria-checked="true"] .rt-thumb{ transform: translateX(36px); }
      .rt-note{ font-size:12px; color:#b3132c; margin-left:4px; }
      .rt-badge{
        font-size:12px; padding:4px 8px; border-radius:999px;
        background:black; color:#b3132c; border:1px solid #b3132c;
      }
      .rt-badge.off{ background:#111; color:#666; border-color:#333; }
    </style>
  </head>
  <body>
    <h1>PhoenixVA ‚Äî Voice + Text Portal</h1>

    <!-- Press-to-talk (hold) + CHAT toggle -->
    <div id="row">
      <button id="pressBtn">üéôÔ∏è Hold to Talk</button>

      <!-- CHAT toggle (framework + realtime loop in this version) -->
      <div class="rt-container" role="group" aria-label="CHAT toggle">
        <span class="rt-label">CHAT</span>
        <div id="rtToggle" class="rt-toggle" role="switch" aria-checked="false" tabindex="0" aria-label="Toggle CHAT mode">
          <div class="rt-thumb"></div>
        </div>
        <span id="rtBadge" class="rt-badge off">OFF</span>
        <span class="rt-note">Realtime loop active when ON</span>
      </div>

      <span id="status"></span>
    </div>

    <!-- Type-to-send -->
    <div id="row">
      <input id="textInput" type="text" placeholder="Type your message‚Ä¶" />
      <button id="sendBtn">Send</button>
    </div>

    <div id="output">Ready.</div>
    <div id="diag"></div>

    <script>
      const pressBtn  = document.getElementById('pressBtn');
      const sendBtn   = document.getElementById('sendBtn');
      const textInput = document.getElementById('textInput');
      const output    = document.getElementById('output');
      const statusEl  = document.getElementById('status');
      const diag      = document.getElementById('diag');

      // CHAT toggle elements/flag (default OFF)
      const rtToggle = document.getElementById('rtToggle');
      const rtBadge  = document.getElementById('rtBadge');
      let realtimeActive = false;

      // Pick a MIME the device actually supports (mobile-safe)
      const CANDIDATE_MIMES = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/ogg;codecs=opus',
        'audio/mp4;codecs=mp4a',
        'audio/mpeg'
      ];
      const supported = CANDIDATE_MIMES.find(t => {
        try { return window.MediaRecorder && MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported(t); }
        catch { return false; }
      }) || 'audio/webm';

      function extFromMime(m) {
        if (!m) return 'webm';
        if (m.includes('mp4')) return 'mp4';
        if (m.includes('ogg')) return 'ogg';
        if (m.includes('mpeg')) return 'mp3';
        return 'webm';
      }
      const chosenExt = extFromMime(supported);

      // ----- Text ‚Üí Chat -----
      async function sendMessage(msg) {
        output.textContent = 'Thinking‚Ä¶';

        // Allow "search:" / "web:" quick route
        const m = msg.trim();
        const isSearch = /^(\s*search:|\s*web:)/i.test(m);
        if (isSearch) {
          const q = m.replace(/^(\s*search:|\s*web:)/i, '').trim();
          if (!q) { output.textContent = 'Please provide a search query.'; return; }

          try {
            const r = await fetch('/api/search', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ q })
            });
            const data = await r.json();

            if (!r.ok || data.error) {
              output.textContent = 'Search error.';
              diag.textContent += `\nSearch error: ${(data && (data.error || data.detail)) || r.statusText}`;
              return;
            }

            const lines = (data.results || []).map((it, i) => `${i+1}. ${it.title}\n${it.link}\n${it.snippet}`).join('\n\n');
            output.textContent = lines || 'No results.';

            // Speak top result
            const top = (data.results || [])[0];
            if (top) {
              try {
                const say = `Top result: ${top.title}. ${top.snippet}`;
                await speak(say);
              } catch {}
            }
            return; // handled via search
          } catch (e) {
            output.textContent = 'Search request failed.';
            diag.textContent += `\nSearch fetch error: ${String(e)}`;
            return;
          }
        }

        // Default path: regular chat
        try {
          const res = await fetch('/api/chat', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ message: msg })
          });
          const data = await res.json();
          const reply = (data.reply || data.error || '(no reply)');
          output.textContent = reply;
          await speak(reply);
        } catch {
          output.textContent = 'Network error';
        }
      }

      // ----- Voice (press-and-hold) ‚Üí Whisper ‚Üí Chat (existing single-shot flow) -----
      let mediaRecorder, audioChunks = [];

      async function startRecording() {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          output.textContent = 'This browser does not support microphone capture.';
          return;
        }
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        try { mediaRecorder = new MediaRecorder(stream, { mimeType: supported }); }
        catch { mediaRecorder = new MediaRecorder(stream); } // last resort

        audioChunks = [];
        mediaRecorder.ondataavailable = e => e.data && e.data.size && audioChunks.push(e.data);
        mediaRecorder.onstop = onStoppedSingleShot;
        mediaRecorder.start();
        diag.textContent = `Recorder MIME: ${supported} | ext: .${chosenExt}`;
      }

      async function onStoppedSingleShot() {
        const blob = new Blob(audioChunks, { type: supported });
        diag.textContent += `\nBlob size: ${blob.size} bytes; type: ${blob.type}`;
        if (!blob.size) {
          statusEl.textContent = 'No audio captured';
          output.textContent = 'No audio captured.';
          return;
        }

        statusEl.textContent = 'Transcribing‚Ä¶';
        output.textContent = 'Transcribing‚Ä¶';

        try {
          const dataUrl = await blobToDataUrl(blob);
          const tr = await fetch('/api/transcribe', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ audio: dataUrl })
          });
          const tdata = await tr.json();

          if (!tr.ok || tdata.error) {
            output.textContent = 'Transcription error.';
            diag.textContent += `\nServer said: ${tdata.error || ''}${tdata.detail ? '\nDetail: ' + tdata.detail : ''}`;
            statusEl.textContent = 'Error';
            return;
          }

          const text = tdata.text || '';
          if (!text) {
            statusEl.textContent = 'No speech detected';
            output.textContent = 'No speech detected.';
            return;
          }

          statusEl.textContent = 'Asking‚Ä¶';
          output.textContent = 'You said: ' + text + '\nThinking‚Ä¶';

          const cr = await fetch('/api/chat', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ message: text })
          });
          const cdata = await cr.json();
          const reply = cdata.reply || '(no reply)';
          output.textContent = 'You said: ' + text + '\nAssistant: ' + reply;
          statusEl.textContent = 'Ready';
          await speak(reply);

        } catch (e) {
          statusEl.textContent = 'Error';
          output.textContent = 'Error during transcription or chat.';
          diag.textContent += `\nClient error: ${String(e)}`;
        }
      }

      function stopRecording() {
        if (mediaRecorder && mediaRecorder.state !== 'inactive') mediaRecorder.stop();
      }

      // Press-and-hold UX (mouse + touch)
      pressBtn.onmousedown = async () => {
        statusEl.textContent = realtimeActive ? 'Recording‚Ä¶ (press) ‚Äî CHAT ON' : 'Recording‚Ä¶ (hold)';
        await startRecording();
      };
      pressBtn.onmouseup = () => {
        statusEl.textContent = 'Processing‚Ä¶';
        stopRecording();
      };
      pressBtn.onmouseleave = () => {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
          statusEl.textContent = 'Processing‚Ä¶';
          stopRecording();
        }
      };
      pressBtn.ontouchstart = async (e) => {
        e.preventDefault();
        statusEl.textContent = realtimeActive ? 'Recording‚Ä¶ (press) ‚Äî CHAT ON' : 'Recording‚Ä¶ (hold)';
        await startRecording();
      };
      pressBtn.ontouchend = (e) => {
        e.preventDefault();
        statusEl.textContent = 'Processing‚Ä¶';
        stopRecording();
      };

      // ====== Realtime loop (when CHAT is ON) ======
      let rtStream = null;
      let rtRecorder = null;
      let rtSpeaking = false;        // true while TTS plays
      let rtBufferText = '';         // accumulated utterance
      let rtSilenceTicks = 0;        // consecutive empty/near-empty chunks
      const CHUNK_MS = 1500;         // ~1.5s chunks
      const SILENCE_LIMIT = 2;       // ~3s of silence to finalize
      const MIN_UTTER_LEN = 6;       // min characters to consider sending
      const END_PUNCT_RE = /[.!?‚Ä¶]$/;

      async function startRealtime() {
        if (rtRecorder) return; // already running
        statusEl.textContent = 'CHAT mode: listening‚Ä¶';
        rtBufferText = '';
        rtSilenceTicks = 0;

        try {
          rtStream = await navigator.mediaDevices.getUserMedia({ audio:true });
          try { rtRecorder = new MediaRecorder(rtStream, { mimeType: supported }); }
          catch { rtRecorder = new MediaRecorder(rtStream); }

          rtRecorder.ondataavailable = onRtChunk;
          rtRecorder.start(CHUNK_MS); // deliver chunks every ~1.5s
          diag.textContent += `\n[CHAT] Realtime started (${supported})`;
        } catch (err) {
          diag.textContent += `\n[CHAT] Failed to start: ${String(err)}`;
          statusEl.textContent = 'CHAT error: mic unavailable';
          stopRealtime();
        }
      }

      async function stopRealtime() {
        try {
          if (rtRecorder && rtRecorder.state !== 'inactive') rtRecorder.stop();
        } catch {}
        rtRecorder = null;

        try {
          if (rtStream) {
            rtStream.getTracks().forEach(t => t.stop());
          }
        } catch {}
        rtStream = null;
        statusEl.textContent = 'CHAT OFF. Press-and-hold active.';
      }

      async function onRtChunk(ev) {
        if (!ev.data || !ev.data.size) { rtSilenceTicks++; checkFinalize(); return; }
        if (rtSpeaking) { /* ignore incoming chunks while speaking to avoid feedback */ return; }

        try {
          const dataUrl = await blobToDataUrl(ev.data);
          const tr = await fetch('/api/transcribe', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ audio: dataUrl })
          });
          const tdata = await tr.json();
          const chunkText = (tdata && tdata.text || '').trim();

          if (chunkText.length === 0) {
            rtSilenceTicks++;
          } else {
            // reset silence, append with spacing if needed
            rtSilenceTicks = 0;
            rtBufferText += (rtBufferText ? ' ' : '') + chunkText;
            output.textContent = `You (live): ${rtBufferText}`;
          }

          checkFinalize();
        } catch (err) {
          diag.textContent += `\n[CHAT] transcribe error: ${String(err)}`;
        }
      }

      function checkFinalize() {
        // Heuristics to decide when the user has finished speaking:
        // 1) Punctuation at end, or
        // 2) A couple of "silent" ticks and we have enough text
        const hasEndPunct = END_PUNCT_RE.test(rtBufferText.trim());
        const longEnough = rtBufferText.trim().length >= MIN_UTTER_LEN;

        if ((hasEndPunct && longEnough) || (rtSilenceTicks >= SILENCE_LIMIT && longEnough)) {
          finalizeUtterance();
        }
      }

      async function finalizeUtterance() {
        const utterance = rtBufferText.trim();
        if (!utterance) { rtBufferText = ''; return; }

        // Reset for next turn immediately to keep loop responsive
        rtBufferText = '';
        rtSilenceTicks = 0;

        // Pause listening during TTS+reply to avoid echo and extra costs:
        await pauseRealtimeDuring(async () => {
          statusEl.textContent = 'Thinking‚Ä¶';
          output.textContent = `You: ${utterance}\nThinking‚Ä¶`;

          try {
            const cr = await fetch('/api/chat', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ message: utterance })
            });
            const cdata = await cr.json();
            const reply = cdata.reply || '(no reply)';
            output.textContent = `You: ${utterance}\nAssistant: ${reply}`;
            await speak(reply);
          } catch (err) {
            diag.textContent += `\n[CHAT] chat error: ${String(err)}`;
            output.textContent = `You: ${utterance}\nAssistant: (error)`;
          } finally {
            statusEl.textContent = 'CHAT mode: listening‚Ä¶';
          }
        });
      }

      async function pauseRealtimeDuring(fn) {
        // Temporarily stop recorder (so mic is released / prevents echo on some devices)
        const wasActive = !!rtRecorder;
        if (wasActive) {
          try { rtRecorder.stop(); } catch {}
          rtRecorder = null;
        }
        try {
          await fn();
        } finally {
          if (realtimeActive) {
            // Restart realtime loop
            await startRealtime();
          }
        }
      }

      async function speak(text) {
        try {
          rtSpeaking = true;
          const ttsResp = await fetch('/api/speak', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ text, voice: "alloy" })
          });
          if (!ttsResp.ok) {
            const err = await ttsResp.json().catch(()=> ({}));
            diag.textContent += `\nTTS error: ${JSON.stringify(err)}`;
            return;
          }
          const audioBuf = await ttsResp.arrayBuffer();
          const blob = new Blob([audioBuf], { type: 'audio/mpeg' });
          const url = URL.createObjectURL(blob);
          await playAudio(url);
        } catch (err) {
          diag.textContent += `\nTTS fetch/playback failed: ${String(err)}`;
        } finally {
          rtSpeaking = false;
        }
      }

      function playAudio(url) {
        return new Promise((resolve) => {
          const audio = new Audio(url);
          audio.onended = () => resolve();
          audio.onerror  = () => resolve();
          audio.play().catch(() => resolve());
        });
      }

      function blobToDataUrl(blob) {
        return new Promise((resolve, reject) => {
          const reader = new FileReader();
          reader.onload = () => resolve(reader.result);
          reader.onerror = reject;
          reader.readAsDataURL(blob);
        });
      }

      // ====== CHAT toggle logic ======
      function setRealtimeActive(on){
        realtimeActive = !!on;
        rtToggle.setAttribute('aria-checked', realtimeActive ? 'true' : 'false');
        rtBadge.textContent = realtimeActive ? 'ON' : 'OFF';
        rtBadge.classList.toggle('off', !realtimeActive);

        if (realtimeActive){
          statusEl.textContent = 'CHAT mode: initializing‚Ä¶';
          startRealtime();
        } else {
          stopRealtime();
        }
      }
      function toggleRealtime(){
        const next = !(rtToggle.getAttribute('aria-checked') === 'true');
        setRealtimeActive(next);
      }
      rtToggle.addEventListener('click', toggleRealtime);
      rtToggle.addEventListener('keydown', (e)=>{
        if (e.key === ' ' || e.key === 'Enter'){ e.preventDefault(); toggleRealtime(); }
      });

      // ====== Text send bindings ======
      sendBtn.onclick = () => {
        const msg = textInput.value.trim();
        if (!msg) return;
        textInput.value = '';
        sendMessage(msg);
      };
      textInput.addEventListener('keydown', e => { if (e.key === 'Enter') sendBtn.click(); });

      // Init (default OFF)
      setRealtimeActive(false);
    </script>
  </body>
</html>
