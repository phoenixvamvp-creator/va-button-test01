<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>PhoenixVA ‚Äî Voice + Text Portal (Mobile-friendly)</title>
    <style>
      body { font-family: system-ui, Arial, sans-serif; margin: 40px; }
      h1 { margin-top: 0; }
      #row { margin: 8px 0; display:flex; align-items:center; gap:10px; flex-wrap:wrap; }
      input[type="text"] { width: 360px; max-width: 100%; padding: 8px; font-size: 16px; }
      button { padding: 10px 16px; font-size: 16px; margin-right: 6px; }
      #output { margin-top: 16px; padding: 12px; border: 1px solid #ddd; min-height: 90px; white-space: pre-wrap; }
      #status { color:#555; }
      #diag { margin-top: 8px; font-size: 12px; color:#444; white-space: pre-wrap; max-height: 260px; overflow:auto; background:#fafafa; border:1px solid #eee; padding:8px; }
      .rt-container{ display:flex; align-items:center; gap:12px; padding:8px 12px; border:2px solid black; border-radius:16px; background:black; }
      .rt-label{ font-weight:700; font-size:18px; color:#b3132c; letter-spacing:.3px; }
      .rt-toggle{ position:relative; width:76px; height:40px; border-radius:999px; background:#222; border:2px solid #b3132c; cursor:pointer; display:inline-flex; align-items:center; padding:2px; transition:background .2s ease; }
      .rt-toggle[aria-checked="true"]{ background:#330000; }
      .rt-thumb{ width:34px; height:34px; border-radius:999px; background:#b3132c; transform: translateX(0); transition: transform .2s ease; }
      .rt-toggle[aria-checked="true"] .rt-thumb{ transform: translateX(36px); }
      .rt-badge{ font-size:12px; padding:4px 8px; border-radius:999px; background:black; color:#b3132c; border:1px solid #b3132c; }
      .rt-badge.off{ background:#111; color:#666; border-color:#333; }
      .rt-note{ font-size:12px; color:#b3132c; margin-left:4px; }
      .pill { font-size:12px; padding:4px 8px; border-radius:999px; background:#efefef; border:1px solid #ddd; cursor:pointer; }
    </style>
  </head>
  <body>
    <h1>PhoenixVA ‚Äî Voice + Text Portal</h1>

    <div id="row">
      <button id="pressBtn">üéôÔ∏è Hold to Talk</button>

      <div class="rt-container" role="group" aria-label="CHAT toggle">
        <span class="rt-label">CHAT</span>
        <div id="rtToggle" class="rt-toggle" role="switch" aria-checked="false" tabindex="0" aria-label="Toggle CHAT mode">
          <div class="rt-thumb"></div>
        </div>
        <span id="rtBadge" class="rt-badge off">OFF</span>
        <span class="rt-note">Realtime voice when ON</span>
      </div>

      <button id="selfTestBtn" class="pill" title="End-to-end probe">Run Self-Test</button>
      <span id="status"></span>
    </div>

    <div id="row">
      <input id="textInput" type="text" placeholder="Type your message‚Ä¶" />
      <button id="sendBtn">Send</button>
    </div>

    <div id="output">Ready.</div>
    <div id="diag">[START] Page loaded.</div>

    <script>
      const pressBtn  = document.getElementById('pressBtn');
      const sendBtn   = document.getElementById('sendBtn');
      const textInput = document.getElementById('textInput');
      const output    = document.getElementById('output');
      const statusEl  = document.getElementById('status');
      const diag      = document.getElementById('diag');
      const rtToggle  = document.getElementById('rtToggle');
      const rtBadge   = document.getElementById('rtBadge');
      const selfTestBtn = document.getElementById('selfTestBtn');

      function log(s){ diag.textContent += `\n${new Date().toLocaleTimeString()}  ${s}`; diag.scrollTop = diag.scrollHeight; }

      // Pick a MediaRecorder MIME that works on the device
      const CANDIDATE_MIMES = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/ogg;codecs=opus',
        'audio/mp4;codecs=mp4a',
        'audio/mpeg'
      ];
      const supported = CANDIDATE_MIMES.find(t => {
        try { return window.MediaRecorder?.isTypeSupported?.(t); } catch { return false; }
      }) || 'audio/webm';

      function blobToDataUrl(blob){
        return new Promise((resolve,reject)=>{
          const fr=new FileReader();
          fr.onload=()=>resolve(fr.result);
          fr.onerror=reject;
          fr.readAsDataURL(blob);
        });
      }

      async function speak(text){
        try{
          const r = await fetch('/api/speak',{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({ text, voice:'alloy' }) });
          const ct = r.headers.get('content-type')||'';
          if(!r.ok){ log(`[TTS] HTTP ${r.status} ${r.statusText}: ${ct}`); return; }
          const buf = await r.arrayBuffer();
          const url = URL.createObjectURL(new Blob([buf],{type:'audio/mpeg'}));
          const a = new Audio(url); a.play().catch(err=>log(`[TTS] play blocked: ${String(err)}`));
        }catch(e){ log(`[TTS] error: ${String(e)}`); }
      }

      // ---------- Helpers ----------
      function mergeTranscript(oldText, newText){
        if (!oldText) return (newText||'').trim();
        if (!newText) return oldText;
        const a = oldText.trim(), b = newText.trim();
        if (b.startsWith(a)) return b;
        if (a.endsWith(b)) return a;
        if (b.endsWith(a)) return b;
        return (a + (a.endsWith(' ')?' ':' ') + b).trim();
      }

      async function primeAudio() {
        try {
          const ctx = new (window.AudioContext || window.webkitAudioContext)();
          const src = ctx.createBufferSource();
          src.buffer = ctx.createBuffer(1, 1, 22050);
          src.connect(ctx.destination);
          src.start(0);
          await new Promise(r => setTimeout(r, 30));
          ctx.close();
          log('[PRIME] audio unlocked');
        } catch (e) { log(`[PRIME] audio unlock error: ${String(e)}`); }
      }

      async function requestMic() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio:{ echoCancellation:true, noiseSuppression:true, autoGainControl:true, channelCount:1 }
          });
          log('[MIC] permission granted');
          return stream;
        } catch (err) {
          log(`[MIC] denied: ${err?.name||'Error'} ${err?.message||''}`);
          throw err;
        }
      }

      // ---------------- Text ‚Üí Chat ----------------
      async function sendMessage(msg){
        output.textContent='Thinking‚Ä¶';
        try{
          const r=await fetch('/api/chat',{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({ message: msg }) });
          const ct=r.headers.get('content-type')||'';
          const data = ct.includes('application/json') ? await r.json() : { error: await r.text() };
          if (!r.ok || data.error){ output.textContent=`Chat error: ${data.error||r.statusText}`; log(`[CHAT] server error: ${data.error||r.statusText}`); return; }
          const reply=data.reply || '(no reply)';
          output.textContent=reply;
          await speak(reply); // no realtime ack for typed chat either
        }catch(e){ output.textContent='Network error'; log(`[CHAT] network error: ${String(e)}`); }
      }
      sendBtn.onclick=()=>{ const msg=textInput.value.trim(); if(!msg) return; textInput.value=''; sendMessage(msg); };
      textInput.addEventListener('keydown', e=>{ if(e.key==='Enter') sendBtn.click(); });

      // ---------------- Hold-to-talk (single shot) ----------------
      let mediaRecorder, audioChunks=[];
      async function startRecording() {
        if (!navigator.mediaDevices?.getUserMedia) { output.textContent='Mic not supported'; return; }
        const stream = await requestMic();
        try { mediaRecorder=new MediaRecorder(stream,{ mimeType: supported }); } catch { mediaRecorder=new MediaRecorder(stream); }
        audioChunks=[];
        mediaRecorder.ondataavailable = e => { if (e.data && e.data.size) { audioChunks.push(e.data); log(`[HOLD] chunk ${e.data.size} bytes`);} };
        mediaRecorder.onstop = onStopped;
        mediaRecorder.start(); // single-shot, stop to flush
        log(`[HOLD] Recorder MIME: ${supported}`);
      }
      async function onStopped(){
        const blob = audioChunks.length ? audioChunks[audioChunks.length-1] : null; // last full blob
        const size = blob ? blob.size : 0;
        log(`[HOLD] final blob ${size} bytes from ${audioChunks.length} chunks`);
        if(!blob || !size){ statusEl.textContent='No audio'; output.textContent='No audio captured.'; return; }
        statusEl.textContent='Transcribing‚Ä¶'; output.textContent='Transcribing‚Ä¶';

        try{
          const dataUrl = await blobToDataUrl(blob);
          const tr = await fetch('/api/transcribe',{ method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ audio: dataUrl }) });
          const ct = tr.headers.get('content-type') || '';
          const tdata = ct.includes('application/json') ? await tr.json() : { error: await tr.text() };
          if (!tr.ok || tdata.error) { output.textContent='Transcription error.'; log(`[HOLD] transcribe server error: ${tdata.error || tr.statusText}`); statusEl.textContent='Error'; return; }

          const text = (tdata.text || '').trim();
          if (!text) { statusEl.textContent='No speech'; output.textContent='No speech detected.'; return; }

          statusEl.textContent = 'Asking‚Ä¶';
          output.textContent = 'You said: ' + text + '\nThinking‚Ä¶';

          const cr = await fetch('/api/chat',{ method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ message: text }) });
          const cct=cr.headers.get('content-type')||'';
          const cdata = cct.includes('application/json') ? await cr.json() : { error: await cr.text() };
          if (!cr.ok || cdata.error){ log(`[HOLD] chat server error: ${cdata.error||cr.statusText}`); output.textContent='Chat error.'; return; }
          const reply = cdata.reply || '(no reply)';
          output.textContent = 'You said: ' + text + '\nAssistant: ' + reply;
          statusEl.textContent = 'Ready';
          await speak(reply);
        }catch(e){
          statusEl.textContent='Error';
          output.textContent='Error during transcription or chat.';
          log(`[HOLD] transcribe network error: ${String(e)}`);
        }
      }
      function stopRecording(){ if(mediaRecorder && mediaRecorder.state!=='inactive') mediaRecorder.stop(); }
      pressBtn.onmousedown = async ()=>{ statusEl.textContent='Recording‚Ä¶ (hold)'; await startRecording(); };
      pressBtn.onmouseup   = ()=>{ statusEl.textContent='Processing‚Ä¶'; stopRecording(); };
      pressBtn.onmouseleave= ()=>{ if(mediaRecorder && mediaRecorder.state==='recording'){ statusEl.textContent='Processing‚Ä¶'; stopRecording(); } };
      pressBtn.ontouchstart= async (e)=>{ e.preventDefault(); statusEl.textContent='Recording‚Ä¶ (hold)'; await startRecording(); };
      pressBtn.ontouchend  = (e)=>{ e.preventDefault(); statusEl.textContent='Processing‚Ä¶'; stopRecording(); };

      // ---------------- CHAT realtime (single-chunk uploads, better silence/acks) ----------------
      let rtStream=null, rtRecorder=null, rtInterval=null, rtSilenceTimer=null;
      let rtChunks=[], rtBufferText='', lastInputAt=0;

      const CHUNK_MS       = 1000; // ~1s chunks ‚Üí valid files, frequent updates
      const SEND_MS        = 600;  // send rhythm
      const SILENCE_MS     = 2200; // consider done after ~2.2s with no input chunks
      const MAX_PER_TICK   = 3;
      const MIN_CHUNK_BYTES= 800;  // accept 1‚Äì3 KB Android chunks; still ignore 0/55/168 byte blobs

      async function startRealtime(){
        if(rtRecorder) return;
        statusEl.textContent='CHAT mode: listening‚Ä¶';
        rtBufferText=''; rtChunks=[]; lastInputAt=0;

        try { await primeAudio(); } catch {}
        try{
          rtStream = await requestMic();
          try{ rtRecorder=new MediaRecorder(rtStream,{ mimeType: supported }); }catch{ rtRecorder=new MediaRecorder(rtStream); }
          rtRecorder.ondataavailable = e => {
            if(e.data && e.data.size){
              rtChunks.push(e.data);
              // Any meaningful chunk arrival = still speaking
              if (e.data.size >= MIN_CHUNK_BYTES) lastInputAt = Date.now();
              log(`[CHAT] chunk ${e.data.size} bytes (queue=${rtChunks.length})`);
            }
          };
          rtRecorder.start(CHUNK_MS);
          log(`[CHAT] recorder started with timeslice ${CHUNK_MS}ms (${supported})`);

          rtInterval = setInterval(sendBatch, SEND_MS);
          if (rtSilenceTimer) clearInterval(rtSilenceTimer);
          rtSilenceTimer = setInterval(checkSilenceAndSend, 250);
        }catch(err){
          log(`[CHAT] start error: ${String(err)}`);
          statusEl.textContent='CHAT error: mic unavailable';
          stopRealtime();
        }
      }
      async function stopRealtime(){
        try{ if(rtInterval) clearInterval(rtInterval); }catch{}
        try{ if(rtSilenceTimer) clearInterval(rtSilenceTimer); }catch{}
        rtInterval=null; rtSilenceTimer=null;
        try{ if(rtRecorder && rtRecorder.state!=='inactive') rtRecorder.stop(); }catch{}
        rtRecorder=null;
        try{ if(rtStream) rtStream.getTracks().forEach(t=>t.stop()); }catch{}
        rtStream=null;
        statusEl.textContent='CHAT OFF. Press-and-hold active.';
      }

      async function sendBatch(){
        try { if (rtRecorder && rtRecorder.state==='recording' && rtChunks.length===0 && rtRecorder.requestData) rtRecorder.requestData(); } catch {}
        if(!rtChunks.length) return;

        const take = Math.min(rtChunks.length, MAX_PER_TICK);
        for (let i=0;i<take;i++){
          const single = rtChunks.shift();
          if (!single || !single.size) continue;

          if (single.size < MIN_CHUNK_BYTES) {
            log(`[CHAT] skipped tiny chunk (${single.size} bytes)`);
            continue;
          }

          // we already updated lastInputAt on arrival; now transcribe
          log(`[CHAT] uploading chunk ${single.size} bytes`);
          const dataUrl = await blobToDataUrl(single);

          try{
            const tr = await fetch('/api/transcribe',{ method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ audio: dataUrl }) });
            const ct = tr.headers.get('content-type') || '';
            const body = ct.includes('application/json') ? await tr.json() : { error: await tr.text() };

            if (!tr.ok || body.error) { log(`[CHAT] transcribe server error: ${body.error || tr.statusText}`); continue; }

            const text = (body.text || '').trim();
            if (text) {
              rtBufferText = mergeTranscript(rtBufferText, text);
              output.textContent = `You (live): ${rtBufferText}`;
              // lastInputAt already refreshed by chunk arrival
            }
          }catch(e){
            log(`[CHAT] transcribe network error: ${String(e)}`);
          }
        }
      }

      async function checkSilenceAndSend(){
        // Only considered silent if we haven't received any acceptable chunk for SILENCE_MS
        if (!rtBufferText) return;
        if (Date.now() - lastInputAt < SILENCE_MS) return;

        const toSend = rtBufferText;
        rtBufferText = '';
        lastInputAt = 0; // reset for next turn

        try{
          output.textContent = `You: ${toSend}\nThinking‚Ä¶`;
          const r = await fetch('/api/chat',{ method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ message: toSend }) });
          const ct=r.headers.get('content-type')||'';
          const data = ct.includes('application/json') ? await r.json() : { error: await r.text() };
          if (!r.ok || data.error){ log(`[CHAT] chat server error: ${data.error||r.statusText}`); output.textContent='Chat error.'; return; }

          const reply = data.reply || '(no reply)';
          output.textContent = `You: ${toSend}\nAssistant: ${reply}`;
          await speak(reply);   // no realtime ‚ÄúOne moment‚Ä¶‚Äù ack
          // Immediately ready for next utterance
        }catch(e){ log(`[CHAT] chat network error: ${String(e)}`); }
      }

      function setRealtimeActive(on){
        const active = !!on;
        rtToggle.setAttribute('aria-checked', active ? 'true':'false');
        rtBadge.textContent = active ? 'ON' : 'OFF';
        rtBadge.classList.toggle('off', !active);
        if (active) startRealtime(); else stopRealtime();
      }
      function toggleRealtime(){ const isOn = rtToggle.getAttribute('aria-checked')==='true'; setRealtimeActive(!isOn); }
      rtToggle.addEventListener('click', toggleRealtime);
      rtToggle.addEventListener('keydown', e=>{ if(e.key===' '||e.key==='Enter'){ e.preventDefault(); toggleRealtime(); } });

      // ---------------- One-click Self-Test (single complete file) ----------------
      selfTestBtn.onclick = async () => {
        log('[SELFTEST] starting‚Ä¶');
        try{
          const r1 = await fetch('/api/chat',{ method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ message:'Say "hello" in five words.' })});
          const t1 = r1.headers.get('content-type')||''; const j1 = t1.includes('application/json') ? await r1.json() : { error: await r1.text() };
          log(`[SELFTEST] chat: ${r1.ok ? 'OK' : 'ERR'} ${j1.error ? j1.error : (j1.reply||'')}`);

          const stream = await requestMic();
          const rec = new MediaRecorder(stream, { mimeType: supported });
          const chunks=[];
          rec.ondataavailable = e=>{ if(e.data && e.data.size) { chunks.push(e.data); log(`[SELFTEST] chunk ${e.data.size} bytes`);} };

          rec.start();                    // record without timeslice
          log('[SELFTEST] recording ~3s‚Ä¶ please say: "testing testing one two"');
          await new Promise(res=>setTimeout(res,3000));
          try { rec.requestData && rec.requestData(); } catch {}
          rec.stop();
          await new Promise(res=>rec.onstop=res);
          stream.getTracks().forEach(t=>t.stop());

          const blob = chunks.length ? chunks[chunks.length-1] : null; // last full chunk
          if (!blob || !blob.size) { log('[SELFTEST] no audio captured'); return; }
          log(`[SELFTEST] final blob ${blob.size} bytes`);

          const dataUrl = await blobToDataUrl(blob);

          const r2 = await fetch('/api/transcribe',{ method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ audio: dataUrl }) });
          const t2 = r2.headers.get('content-type')||''; const j2 = t2.includes('application/json') ? await r2.json() : { error: await r2.text() };
          log(`[SELFTEST] transcribe: ${r2.ok ? 'OK' : 'ERR'} ${j2.error ? j2.error : (j2.text||'')}`);

          if (j2.text){
            const r3 = await fetch('/api/chat',{ method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ message: `You heard: ${j2.text}. Reply with a short acknowledgement.` }) });
            const t3 = r3.headers.get('content-type')||''; const j3 = t3.includes('application/json') ? await r3.json() : { error: await r3.text() };
            log(`[SELFTEST] chat(replay): ${r3.ok ? 'OK' : 'ERR'} ${j3.error ? j3.error : (j3.reply||'')}`);
            if (j3.reply) await speak(j3.reply);
          }
          log('[SELFTEST] done.');
        }catch(e){ log(`[SELFTEST] error: ${String(e)}`); }
      };

      // init
      log(`[INIT] MediaRecorder: ${supported}`);
    </script>
  </body>
</html>
