<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Phoenix VA — Realtime</title>
  <meta name="color-scheme" content="light dark" />
  <style>
    :root {
      --navy: #0B1B34;
      --card: #0F223F;
      --text: #E8EEF9;
      --muted: #9FB1D1;
      --accent: #FFFFFF;
      --btn-bg: #001F3F;
      --btn-tx: #FFFFFF;
    }
    * { box-sizing: border-box; }
    html, body { height: 100%; }
    body {
      margin: 0;
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Inter, Arial, sans-serif;
      background: var(--navy);
      color: var(--text);
      display: grid;
      place-items: center;
      min-height: 100svh;
    }
    .wrap { width: 100%; max-width: 720px; padding: 20px; display: grid; gap: 16px; }
    .brand { display: grid; place-items: center; gap: 10px; text-align: center; }
    .brand img {
      width: 96px; height: auto; display: block;
      filter: drop-shadow(0 6px 18px rgba(0,0,0,.25));
      user-select: none;
    }
    .brand h1 { margin: 0; font-size: 18px; font-weight: 600; color: var(--muted); letter-spacing: .3px; }
    .card {
      background: color-mix(in oklab, var(--card) 90%, black 10%);
      border: 1px solid rgba(255,255,255,.08);
      border-radius: 14px;
      padding: 14px;
      box-shadow: 0 12px 30px rgba(0,0,0,.25);
    }
    .row { display: flex; gap: 10px; flex-wrap: wrap; align-items: center; }
    button, .btn {
      appearance: none; border: none; background: #F4F6FC; color: #0B1B34;
      padding: 10px 14px; border-radius: 12px; font-weight: 700; cursor: pointer;
      transition: transform .04s ease, opacity .2s ease, background .2s ease;
    }
    button:active { transform: translateY(1px); }
    button[disabled] { opacity: .6; cursor: not-allowed; }
    #voiceToggle {
      background: var(--btn-bg); color: var(--btn-tx);
      display: inline-flex; align-items: center; gap: 10px;
      padding: 12px 18px; border-radius: 16px;
    }
    #voiceToggle img { width: 28px; height: 28px; object-fit: contain; display: block; pointer-events: none; user-select: none; }
    #voiceToggle:hover { background: #003366; }
    .btn-outline { background: transparent; color: var(--accent); border: 1px solid rgba(255,255,255,.2); }
    input[type="text"] {
      flex: 1 1 220px; background: rgba(255,255,255,.06); color: var(--text);
      border: 1px solid rgba(255,255,255,.15); border-radius: 10px; padding: 10px 12px; outline: none;
    }
    input::placeholder { color: rgba(255,255,255,.5); }
    #log {
      white-space: pre-wrap; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
      font-size: 12px; line-height: 1.4; color: #CFE2FF; max-height: 280px; overflow: auto;
      background: rgba(0,0,0,.25); border-radius: 10px; padding: 12px; border: 1px solid rgba(255,255,255,.08);
    }
    .hint { color: var(--muted); font-size: 12px; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="brand">
      <img src="/public/logo.png" alt="Phoenix VA Logo" />
      <h1>Phoenix VA — Realtime</h1>
    </div>

    <div class="card">
      <div class="row" style="justify-content:space-between">
        <div class="row">
          <button id="voiceToggle">
            <img src="/public/logo.png" alt="Phoenix VA Logo" width="56" height="56" />
            <span id="voiceLabel">Start</span>
          </button>

          <button id="googleConnect" class="btn-outline" title="Connect Google">Connect Google</button>
        </div>
        <span class="hint" id="status">idle</span>
      </div>

      <div class="row" style="margin-top:10px">
        <input id="textInput" type="text" placeholder="Ask me anything">
        <button id="sendText">Send</button>
      </div>

      <audio id="assistantAudio" autoplay playsinline style="display:none"></audio>
      <div id="log" style="margin-top:12px"></div>
    </div>
  </div>

  <script type="module">
    const logEl = document.getElementById('log');
    const statusEl = document.getElementById('status');
    const btn = document.getElementById('voiceToggle');
    const btnLabel = document.getElementById('voiceLabel');
    const btnGoogle = document.getElementById('googleConnect');
    const inputEl = document.getElementById('textInput');
    const sendBtn = document.getElementById('sendText');
    const setSendReady = (ready) => { sendBtn.disabled = !ready; };
    setSendReady(false);

    const audioEl = document.getElementById('assistantAudio');

    const log = (...a) => {
      const s = a.map(x => typeof x === 'string' ? x : JSON.stringify(x, null, 2)).join(' ');
      logEl.textContent += s + '\n';
      logEl.scrollTop = logEl.scrollHeight;
      console.log(...a);
    };
    const setStatus = (s) => { statusEl.textContent = s; };

    let pc = null, mic = null, dc = null, live = false;

    // Response state management
    // __responseActive: whether we have created a response that is currently active
    // __waitingForResponseId: we created a response and are waiting for server to send response.created to capture id
    // __lastResponseCreatedId: the server-assigned response id (used to match done events)
    // __pendingToolResults: queue of tool results that arrived while a response was active
    window.__responseActive = false;
    window.__waitingForResponseId = false;
    window.__lastResponseCreatedId = null;
    window.__pendingToolResults = [];

    // Safety fallback: clear responseActive after this timeout (ms) if not cleared by server events
    const RESPONSE_ACTIVE_FALLBACK_MS = 12000;
    let __responseActiveFallbackTimer = null;
    function setResponseActive(active) {
      window.__responseActive = !!active;
      if (active) {
        // start fallback timer to avoid permanent lock
        clearTimeout(__responseActiveFallbackTimer);
        __responseActiveFallbackTimer = setTimeout(() => {
          if (window.__responseActive) {
            log('[WARN] responseActive fallback fired; clearing flag');
            window.__responseActive = false;
            window.__waitingForResponseId = false;
            window.__lastResponseCreatedId = null;
            flushPendingToolResults();
          }
        }, RESPONSE_ACTIVE_FALLBACK_MS);
      } else {
        clearTimeout(__responseActiveFallbackTimer);
        __responseActiveFallbackTimer = null;
      }
    }

    async function sendResponseInstructions(text) {
      if (!dc || dc.readyState !== 'open') {
        log('[WARN] DC not open; cannot send response.create');
        return;
      }
      if (window.__responseActive) {
        // Queue the result to send once current response completes
        window.__pendingToolResults.push({ text });
        log('[INFO] response active — queued tool result');
        return;
      }
      try {
        window.__waitingForResponseId = true;
        setResponseActive(true);
        // send single response.create with instructions; do NOT send a second empty create
        dc.send(JSON.stringify({
          type: 'response.create',
          response: { instructions: text }
        }));
        log('[DC=>] response.create (tool output sent)');
      } catch (e) {
        log('[ERR] sendResponseInstructions send failed:', e?.message || e);
        // if send fails, clear active to avoid lock
        setResponseActive(false);
        window.__waitingForResponseId = false;
      }
    }

    function flushPendingToolResults() {
      if (!dc || dc.readyState !== 'open') {
        log('[WARN] DC not open; cannot flush pending tool results');
        return;
      }
      if (window.__responseActive) {
        log('[INFO] still response active; will flush later');
        return;
      }
      const item = window.__pendingToolResults.shift();
      if (item) {
        log('[INFO] flushing queued tool result');
        sendResponseInstructions(item.text);
      }
    }

    btnGoogle.addEventListener('click', () => {
      window.location.href = '/api/google.js?op=start';
    });

    sendBtn.addEventListener('click', () => {
      const text = (inputEl.value || '').trim();
      if (!text) return;
      if (!dc || dc.readyState !== 'open') {
        log('[WARN] DataChannel not open yet; cannot send text.');
        return;
      }
      try {
        dc.send(JSON.stringify({ type: 'response.create', response: { instructions: text }}));
        log('[TX] text prompt → response.create');
      } catch (e) {
        log('[ERR] send text:', e?.message || e);
      }
    });

    async function startRealtime() {
      try {
        setStatus('requesting mic…');
        try {
          if ('permissions' in navigator && navigator.permissions?.query) {
            const p = await navigator.permissions.query({ name: 'microphone' });
            log('[PERM] microphone:', p.state);
          }
        } catch (e) {}

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mic = stream;
        const micTrack = mic.getTracks()[0];

        pc = new RTCPeerConnection();
        pc.oniceconnectionstatechange = () => log('ICE:', pc.iceConnectionState);
        pc.onconnectionstatechange = () => log('PC:', pc.connectionState);
        pc.ontrack = (e) => {
          log('[RT] ontrack: remote audio');
          audioEl.srcObject = e.streams[0];
          audioEl.play().catch(err => log('[AUDIO] play blocked:', err?.message || err));
        };

        const tx = pc.addTransceiver('audio', { direction: 'sendrecv' });
        try { await tx.sender.replaceTrack(micTrack); } catch {}
        if (tx.sender.setStreams) { try { tx.sender.setStreams(mic); } catch {} }

        dc = pc.createDataChannel('oai-events');

        let sessionIsCreated = false;
        let sessionIsUpdated = false;

        dc.onopen = () => {
          log('[DC] open');
          setSendReady(true);
          setStatus('waiting-for-session'); // not 'ready' yet
        };

        dc.onmessage = (evt) => {
          let msg;
          try { msg = JSON.parse(evt.data); } catch (e) { return; }

          log('[DC<=]', msg);

          // If the server reports a response created, capture id for matching done events
          if (msg.type === 'response.created' && msg.response && msg.response.id) {
            if (window.__waitingForResponseId) {
              window.__lastResponseCreatedId = msg.response.id;
              window.__waitingForResponseId = false;
              log('[INFO] captured response id', window.__lastResponseCreatedId);
            }
          }

          // Clear __responseActive when the response finishes (match by response id when available)
          // Accept a few possible done/completed event names
          if (msg.type === 'response.done' && msg.response_id) {
            if (!window.__lastResponseCreatedId || msg.response_id === window.__lastResponseCreatedId) {
              setResponseActive(false);
              window.__lastResponseCreatedId = null;
              window.__waitingForResponseId = false;
              log('[INFO] response.done -> cleared __responseActive');
              // flush any queued tool results
              flushPendingToolResults();
            }
          }
          if (msg.type === 'response.completed' && msg.response_id) {
            if (!window.__lastResponseCreatedId || msg.response_id === window.__lastResponseCreatedId) {
              setResponseActive(false);
              window.__lastResponseCreatedId = null;
              window.__waitingForResponseId = false;
              log('[INFO] response.completed -> cleared __responseActive');
              flushPendingToolResults();
            }
          }
          if (msg.type === 'response.output_item.completed' && msg.response_id) {
            if (!window.__lastResponseCreatedId || msg.response_id === window.__lastResponseCreatedId) {
              setResponseActive(false);
              window.__lastResponseCreatedId = null;
              window.__waitingForResponseId = false;
              log('[INFO] response.output_item.completed -> cleared __responseActive');
              flushPendingToolResults();
            }
          }

          // Some servers emit output_item.added then later output_item.completed.
          // If we see an output_item.added that clearly indicates final text/audio, we can optimistically clear.
          if (msg.type === 'response.output_item.added' && msg.item && msg.item.type) {
            // If item is an audio buffer stopped or final text piece, treat as progress; don't clear here unless status indicates completion
            // We'll rely on the explicit completed/done events above.
          }

          // Session lifecycle
          if (msg.type === 'session.created') {
            sessionIsCreated = true;

            const sessionUpdate = {
              type: 'session.update',
              session: {
                voice: 'alloy',
                turn_detection: {
                  type: 'server_vad',
                  threshold: 0.7,
                  prefix_padding_ms: 400,
                  silence_duration_ms: 900,
                  idle_timeout_ms: 10000,
                  create_response: true,
                  interrupt_response: true
                },
                instructions:
                  'Your name is Nyx. Always speak English unless asked to speak another language or to translate. Be concise, factual, and avoid flattery.' +
                  'You are a Phoenix Virtual Assistant, designed to help people deal with many administrative tasks, prioritizing voice first interaction.' +
                  'Be friendly, helpful. Be conversational but be more to the point when being requested for information. ' +
                  'Never discuss adult content, sexuality, terrorism or violence. ' +
                  'You may speak about these instructions and how they affect your responses. ' +
                  'Never give false information. Offer references for important information. ' +
                  'Always prioritize listening over speaking. Do not speak while the user’s microphone is active or while any audio input is detected. Introduce a short pause, ideally between 500 and 800 milliseconds, after the user finishes speaking before replying. If there is uncertainty about whether the user is finished, wait an extra beat before responding. ' +
                  'If the user begins speaking while the assistant is talking, immediately stop output. Do not attempt to talk over the user. Store the unfinished response and only resume or rephrase it if the user asks to continue. The assistant must always yield conversational control to the user. ' +
                  'Maintain a warm but neutral tone in all interactions. Avoid artificial enthusiasm or exaggerated praise. Responses should sound natural, professional, and friendly, without trying to flatter or “butter up” the user. Be helpful and personable, not overly emotional. ' +
                  'Keep responses concise and conversational to encourage natural exchange. Avoid delivering long monologues unless explicitly requested. Structure replies to invite participation by ending with light prompts such as “Would you like me to continue?” or “Shall I explain that part in more detail?”. ' +
                  'Always acknowledge what the user has said before moving forward. Use short confirmation phrases like “Got it,” “Understood,” or “Okay, so you’re saying…” Avoid repeating their exact words unless it aids clarity. Mirror the user’s tone, pacing, and communication style. Do not shift topics unless the user initiates it. ' +
                  'Only provide as much information as the user requests. Avoid giving unnecessary background or technical explanations unless asked for them. Never interrupt the user mid-sentence or mid-thought. Allow silence to exist naturally without trying to fill it. ' +
                  'When the user asks about Google Drive, Google Docs, or Google Sheets, you MUST call the tools and wait for their results. ' +
                  'Never guess or describe file contents without a successful tool call. ' +
                  'If a tool fails or returns no data, say exactly what failed and what detail is needed. ' +
                  'When you read a sheet, state the exact file name, tab, and range you used. ' +
                  'When you edit a cell, state the file name, tab, and cell you modified. ' +
                  'Prefer tools over free-text answers for anything involving Drive/Docs/Sheets.'
              }
            };
            try {
              dc.send(JSON.stringify(sessionUpdate));
              log('[DC=>] session.update sent');
            } catch (e) {
              log('[ERR] sending session.update', e?.message || e);
            }
            return;
          }

          if (msg.type === 'session.updated') {
            sessionIsUpdated = true;
            setStatus('ready');

            if (!window.__greeted) {
              window.__greeted = true;
              // First reply only after update is confirmed
              try {
                dc.send(JSON.stringify({
                  type: 'response.create',
                  response: { instructions: 'Hello! Nyx is ready.' }
                }));
                log('[DC=>] response.create (greeting)');
              } catch (e) {
                log('[ERR] greeting send failed', e?.message || e);
              }
            }

            // Register Docs tools AFTER instructions are applied
            if (!window.__toolsRegistered) {
              window.__toolsRegistered = true;

              // Persistent buffer for streamed tool-call arguments
              window.toolArgBuf = Object.create(null);

              // Dispatcher: routes tool calls to your backend
              window.handleToolCall = async function handleToolCall(name, args, callId) {
                try {
                  let url = '', body = {};

                  if (name === 'docs_read') {
                    url = '/api/workspace.js?action=docs.read';
                    body = {
                      docId: (args.docId || '').toString(),
                      docName: (args.docName || '').toString(),
                      folderName: (args.folderName || '').toString()
                    };
                  } else if (name === 'docs_createappend') {
                    url = '/api/workspace.js?action=docs.createappend';
                    body = {
                      docName: (args.docName || '').toString(),
                      folderName: (args.folderName || '').toString(),
                      text: (args.text ?? '').toString()
                    };
                  } else {
                    const out = { error: `Unsupported tool: ${name}` };
                    // Return error to assistant as readable instructions (safe, accepted shape)
                    await sendResponseInstructions(JSON.stringify(out));
                    return;
                  }

                  const r = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    credentials: 'include',
                    body: JSON.stringify(body)
                  });

                  const text = await r.text();
                  log('[TOOL]', name, r.status, text.slice(0, 400));

                  // Send doc content as normal response.create.instructions (server accepted)
                  await sendResponseInstructions(text);
                } catch (e) {
                  const out = { error: String(e?.message || e) };
                  await sendResponseInstructions(JSON.stringify(out));
                }
              };

              // Register just the Docs tools
              const toolsUpdate = {
                type: 'session.update',
                session: {
                  tool_choice: 'auto',
                  tools: [
                    {
                      type: 'function',
                      name: 'docs_read',
                      description: 'Read a Google Doc by name (optional folderName). Returns contents.',
                      parameters: {
                        type: 'object',
                        properties: {
                          docId: { type: 'string', description: 'Optional Google Doc ID (preferred if known)' },
                          docName: { type: 'string', description: 'Document name to read' },
                          folderName: { type: 'string', description: 'Optional parent folder; omit for root' }
                        },
                        required: ['docName']
                      }
                    },
                    {
                      type: 'function',
                      name: 'docs_createappend',
                      description: 'Create a Doc in root (or optional folder) if missing, then append text to it.',
                      parameters: {
                        type: 'object',
                        properties: {
                          docName: { type: 'string', description: 'Target document name' },
                          folderName: { type: 'string', description: 'Optional parent folder; omit for root' },
                          text: { type: 'string', description: 'Text to append (newline is added if missing)' }
                        },
                        required: ['docName', 'text']
                      }
                    }
                  ]
                }
              };

              try {
                dc.send(JSON.stringify(toolsUpdate));
                log('[DC=>] tools session.update (Docs) sent');
              } catch (e) {
                log('[ERR] sending tools session.update', e?.message || e);
              }
            }
            return;
          }

          // Handle streamed tool-call arguments (only after tools are registered)
          {
            const t = msg.type;

            const isDelta =
              t === 'response.function_call_arguments.delta' ||
              t === 'response.function_call.arguments.delta' ||
              t === 'response.tool_call.delta' ||
              t === 'response.tool_call.arguments.delta';

            const isDone =
              t === 'response.function_call_arguments.done' ||
              t === 'response.function_call.completed' ||
              t === 'response.tool_call.completed' ||
              t === 'response.tool_call.arguments.done';

            if ((isDelta || isDone) && !window.__toolsRegistered) {
              // Ignore any early tool-call fragments until tools are registered
              return;
            }

            if (isDelta) {
              const id = msg.call_id || msg.id;
              const frag =
                (typeof msg.delta === 'string' ? msg.delta :
                 typeof msg.arguments === 'string' ? msg.arguments : '');
              window.toolArgBuf = window.toolArgBuf || Object.create(null);
              window.toolArgBuf[id] = (window.toolArgBuf[id] || '') + frag;
              return;
            }

            if (isDone) {
              const id = msg.call_id || msg.id;
              const name = msg.name || msg.tool_name;
              const argsStr =
                (typeof msg.arguments === 'string' ? msg.arguments : (window.toolArgBuf ? window.toolArgBuf[id] : '')) || '{}';
              if (window.toolArgBuf) delete window.toolArgBuf[id];

              let args = {};
              try { args = JSON.parse(argsStr); } catch (e) { args = {}; }
              if (typeof window.handleToolCall === 'function') {
                window.handleToolCall(name, args, id);
              }
              return;
            }
          }

          if (msg.type === 'error') {
            console.error('[Realtime ERROR]', msg.error || msg);
            setStatus('error');
            return;
          }
        };

        dc.onerror = (e) => log('[DC] error', e);
        dc.onclose = () => { log('[DC] closed'); setSendReady(false); setStatus('disconnected'); };

        setStatus('creating offer…');
        const offer = await pc.createOffer({ offerToReceiveAudio: 1 });
        await pc.setLocalDescription(offer);

        const res = await fetch('/api/realtime/offer.js', {
          method: 'POST',
          headers: { 'Content-Type': 'application/sdp' },
          body: offer.sdp,
          credentials: 'include'
        });
        const answer = await res.text();
        log('[HTTP] /api/realtime/offer →', res.status);
        if (!res.ok) {
          try { log('[ERR]', JSON.parse(answer)); } catch { log('[ERR]', answer); }
          throw new Error('Offer→Answer failed');
        }

        await pc.setRemoteDescription({ type: 'answer', sdp: answer });
        setStatus('connected — waiting for channel…');
        log('[RT] connected; speak to the assistant…');
      } catch (e) {
        setStatus('error');
        log('[EXC] startRealtime:', e?.message || e);
        throw e;
      }
    }

    function stopRealtime() {
      try { pc?.getSenders().forEach(s => s.track?.stop()); pc?.close(); } catch {}
      try { mic?.getTracks().forEach(t => t.stop()); } catch {}
      pc = null; mic = null; dc = null; audioEl.srcObject = null;
      setSendReady(false);
      setStatus('idle');
      // clear response state and pending queue when stopping
      window.__responseActive = false;
      window.__waitingForResponseId = false;
      window.__lastResponseCreatedId = null;
      window.__pendingToolResults = [];
      log('[RT] stopped');
    }

    async function ensureGoogleAuth() {
      try {
        const r = await fetch('/api/google.js?op=status', { credentials: 'include' });
        const data = await r.json();
        log('[AUTH]', data);
        if (data.connected && !data.refresh_problem) return true;
        setStatus('connecting Google…');
        window.location.href = '/api/google.js?op=start';
        return false;
      } catch (e) {
        log('[AUTH] status error:', e?.message || e);
        window.location.href = '/api/google.js?op=start';
        return false;
      }
    }

    btn.addEventListener('click', async () => {
      btn.disabled = true;
      try {
        if (!live) {
          btnLabel.textContent = 'Connecting…';
          const ok = await ensureGoogleAuth();
          if (!ok) return;
          await startRealtime();
          live = true;
          btnLabel.textContent = 'Stop';
        } else {
          stopRealtime();
          live = false;
          btnLabel.textContent = 'Start';
        }
      } catch {
        stopRealtime();
        live = false;
        btnLabel.textContent = 'Start';
      } finally {
        btn.disabled = false;
      }
    });

    inputEl.addEventListener('keydown', (e) => {
      if (e.key === 'Enter') { e.preventDefault(); if (!sendBtn.disabled) sendBtn.click(); }
    });
  </script>
</body>
</html>
