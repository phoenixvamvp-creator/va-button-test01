<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>PhoenixVA ‚Äî Voice + Text Portal</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    :root { --scarlet:#b3132c; }
    body { font-family: system-ui, Arial, sans-serif; margin: 24px; }
    h1 { margin: 0 0 12px; }
    .row { display:flex; gap:12px; align-items:center; flex-wrap:wrap; margin: 8px 0; }
    input[type="text"] { flex: 1 1 340px; max-width: 100%; padding: 10px; font-size: 16px; border:1px solid #ddd; border-radius:8px; }
    button { padding: 10px 14px; font-size: 15px; border-radius:10px; cursor:pointer; }
    #output { margin-top: 12px; padding: 12px; border: 1px solid #ddd; min-height: 100px; white-space: pre-wrap; border-radius:8px; }
    #diag { margin-top: 10px; padding:8px; border:1px solid #eee; background:#fafafa; white-space:pre-wrap; max-height: 260px; overflow:auto; border-radius:8px; font-size:12px; }
    #status { color:#666; }
    /* CHAT toggle */
    .toggle-wrap { display:flex; align-items:center; gap:10px; padding:8px 12px; border:2px solid #000; border-radius:16px; background:#000; }
    .toggle-label { color: var(--scarlet); font-weight:700; }
    .toggle { position:relative; width:76px; height:40px; border-radius:999px; background:#222; border:2px solid var(--scarlet); cursor:pointer; padding:2px; }
    .thumb { width:34px; height:34px; background:var(--scarlet); border-radius:999px; transform:translateX(0); transition:transform .2s; }
    .toggle[aria-checked="true"] .thumb { transform:translateX(36px); }
    .badge { font-size:12px; padding:4px 8px; border-radius:999px; border:1px solid var(--scarlet); color:var(--scarlet); background:#000; }
    .badge.off { border-color:#333; color:#666; }
    .pill { font-size:12px; padding:6px 10px; border-radius:999px; border:1px solid #ddd; background:#f3f3f3; }
  </style>
</head>
<body>
  <h1>PhoenixVA ‚Äî Voice + Text Portal</h1>

  <div class="row">
    <button id="holdBtn">üéôÔ∏è Hold to Talk</button>

    <div class="toggle-wrap" role="group" aria-label="Realtime chat toggle">
      <span class="toggle-label">CHAT</span>
      <div id="chatToggle" class="toggle" role="switch" aria-checked="false" tabindex="0" aria-label="Toggle realtime chat"><div class="thumb"></div></div>
      <span id="chatBadge" class="badge off">OFF</span>
      <span style="color:var(--scarlet); font-size:12px;">Realtime voice when ON</span>
    </div>

    <button id="selfTestBtn" class="pill" title="End-to-end probe">Run Self-Test</button>
    <span id="status"></span>
  </div>

  <div class="row">
    <input id="textInput" type="text" placeholder="Type your message‚Ä¶" />
    <button id="sendBtn">Send</button>
  </div>

  <div id="output">Ready.</div>
  <div id="diag">[START] Page loaded.</div>

<script>
/* =============================================================================
   SECTION 0 ‚Äî LIGHTWEIGHT LOGGER
============================================================================= */
const diag = document.getElementById('diag');
function log(msg){ diag.textContent += `\n${new Date().toLocaleTimeString()}  ${msg}`; diag.scrollTop = diag.scrollHeight; }

/* =============================================================================
   SECTION 1 ‚Äî UI ELEMENTS & CONSTANTS
   (All wiring to buttons / toggle lives here)
============================================================================= */
const holdBtn    = document.getElementById('holdBtn');
const chatToggle = document.getElementById('chatToggle');
const chatBadge  = document.getElementById('chatBadge');
const selfTestBtn= document.getElementById('selfTestBtn');
const sendBtn    = document.getElementById('sendBtn');
const textInput  = document.getElementById('textInput');
const statusEl   = document.getElementById('status');
const output     = document.getElementById('output');

// Pick a MediaRecorder MIME that actually works on device
const CANDIDATE_MIMES = [
  'audio/webm;codecs=opus', 'audio/webm',
  'audio/ogg;codecs=opus', 'audio/mp4;codecs=mp4a',
  'audio/mpeg'
];
const supported = CANDIDATE_MIMES.find(t => {
  try { return window.MediaRecorder?.isTypeSupported?.(t); } catch { return false; }
}) || 'audio/webm';
log(`[INIT] MediaRecorder uses ${supported}`);

/* =============================================================================
   SECTION 2 ‚Äî UTILS (Audio priming, dataURL helper, transcript merge)
============================================================================= */
function blobToDataUrl(blob){
  return new Promise((resolve,reject)=>{
    const fr=new FileReader();
    fr.onload=()=>resolve(fr.result);
    fr.onerror=reject;
    fr.readAsDataURL(blob);
  });
}
function mergeTranscript(a,b){
  if(!a) return (b||'').trim();
  if(!b) return a;
  const x=a.trim(), y=b.trim();
  if(y.startsWith(x)) return y;
  if(x.endsWith(y)) return x;
  if(y.endsWith(x)) return y;
  return (x + (x.endsWith(' ')?' ':' ') + y).trim();
}
async function primeAudio(){
  try{
    const ctx = new (window.AudioContext||window.webkitAudioContext)();
    const src = ctx.createBufferSource(); src.buffer = ctx.createBuffer(1,1,22050);
    src.connect(ctx.destination); src.start(0);
    await new Promise(r=>setTimeout(r,30)); ctx.close();
    log('[PRIME] Audio unlocked');
  }catch(e){ log(`[PRIME] error: ${String(e)}`); }
}
async function getMic(){
  try{
    const stream = await navigator.mediaDevices.getUserMedia({
      audio:{ echoCancellation:true, noiseSuppression:true, autoGainControl:true, channelCount:1 }
    });
    log('[MIC] permission granted');
    return stream;
  }catch(e){ log(`[MIC] denied: ${e?.name||'Error'} ${e?.message||''}`); throw e; }
}

/* =============================================================================
   SECTION 3 ‚Äî SERVER CALLS (chat, transcribe, speak)
============================================================================= */
async function callChat(message){
  const r = await fetch('/api/chat',{ method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ message }) });
  const ct=r.headers.get('content-type')||''; const j = ct.includes('application/json')? await r.json() : { error: await r.text() };
  if(!r.ok || j.error) throw new Error(j.error || r.statusText);
  return j.reply || '';
}
async function callTranscribe(dataUrl){
  const r = await fetch('/api/transcribe',{ method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ audio: dataUrl }) });
  const ct=r.headers.get('content-type')||''; const j = ct.includes('application/json')? await r.json() : { error: await r.text() };
  if(!r.ok || j.error) throw new Error(j.error || r.statusText);
  return (j.text||'').trim();
}
async function callSpeak(text){
  const r = await fetch('/api/speak',{ method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({ text, voice:'alloy' }) });
  if(!r.ok){ log(`[TTS] HTTP ${r.status} ${r.statusText}`); return; }
  const url = URL.createObjectURL(new Blob([await r.arrayBuffer()],{type:'audio/mpeg'}));
  const a = new Audio(url); a.play().catch(err=>log(`[TTS] play blocked: ${String(err)}`));
}

/* =============================================================================
   SECTION 4 ‚Äî TYPE TO CHAT (baseline)
============================================================================= */
sendBtn.onclick = async ()=>{
  const msg=textInput.value.trim(); if(!msg) return;
  textInput.value='';
  output.textContent='Thinking‚Ä¶';
  try{
    const reply=await callChat(msg);
    output.textContent=reply;
    await callSpeak(reply);
  }catch(e){ output.textContent='Chat error'; log(`[CHAT] ${String(e)}`); }
};
textInput.addEventListener('keydown',e=>{ if(e.key==='Enter') sendBtn.click(); });

/* =============================================================================
   SECTION 5 ‚Äî HOLD-TO-TALK (single shot): press, speak, release
============================================================================= */
let holdRecorder, holdChunks=[];
holdBtn.onmousedown = holdStart;
holdBtn.ontouchstart = e=>{e.preventDefault(); holdStart();};
holdBtn.onmouseup    = holdStop;
holdBtn.ontouchend   = e=>{e.preventDefault(); holdStop();};
holdBtn.onmouseleave = ()=>{ if(holdRecorder && holdRecorder.state==='recording') holdStop(); };

async function holdStart(){
  statusEl.textContent='Recording‚Ä¶ (hold)';
  const stream = await getMic();
  try{ holdRecorder = new MediaRecorder(stream,{ mimeType:supported }); } catch { holdRecorder = new MediaRecorder(stream); }
  holdChunks=[];
  holdRecorder.ondataavailable = ev=>{ if(ev.data && ev.data.size) { holdChunks.push(ev.data); log(`[HOLD] chunk ${ev.data.size} bytes`);} };
  holdRecorder.onstop = async ()=>{
    const blob = holdChunks[holdChunks.length-1]; // use last complete chunk
    if(!blob || !blob.size){ statusEl.textContent='No audio'; output.textContent='No audio captured.'; return; }
    statusEl.textContent='Transcribing‚Ä¶'; output.textContent='Transcribing‚Ä¶';
    try{
      const text = await callTranscribe(await blobToDataUrl(blob));
      if(!text){ output.textContent='No speech detected.'; statusEl.textContent='Ready'; return; }
      output.textContent='You said: ' + text + '\nThinking‚Ä¶';
      const reply = await callChat(text);
      output.textContent = 'You said: ' + text + '\nAssistant: ' + reply;
      statusEl.textContent='Ready';
      await callSpeak(reply);
    }catch(e){ output.textContent='Error'; statusEl.textContent='Ready'; log(`[HOLD] ${String(e)}`); }
  };
  holdRecorder.start(); // single-shot. stop() flushes a complete file
  log(`[HOLD] start (${supported})`);
}
function holdStop(){ statusEl.textContent='Processing‚Ä¶'; try{ holdRecorder.stop(); }catch{} }

/* =============================================================================
   SECTION 6 ‚Äî REALTIME CHAT (keeps listening, multi-turn)
   Key points:
   - Never concatenate MediaRecorder chunks.
   - Ignore tiny blobs (< 800 B) that aren‚Äôt valid audio files.
   - Use *chunk arrival* as ‚Äústill speaking‚Äù signal; finalize after SILENCE_MS with no arrivals.
============================================================================= */
const CHUNK_MS        = 900;   // recorder emits ~1s chunks
const SEND_TICK_MS    = 500;   // how often we try to send pending chunks
const SILENCE_MS      = 2200;  // finalize if no meaningful chunk for this long
const MIN_CHUNK_BYTES = 800;   // accept small Android chunks; ignore 0/55/168 B

let rtStream=null, rtRecorder=null;
let rtQueue=[], rtLiveText='', rtSendTimer=null, rtSilenceTimer=null, lastChunkAt=0;

function setChatToggle(on){
  chatToggle.setAttribute('aria-checked', on?'true':'false');
  chatBadge.textContent = on ? 'ON' : 'OFF';
  chatBadge.classList.toggle('off', !on);
}
chatToggle.addEventListener('click', ()=> toggleRealtime());
chatToggle.addEventListener('keydown', e=>{ if(e.key===' '||e.key==='Enter'){ e.preventDefault(); toggleRealtime(); } });

async function toggleRealtime(){
  const on = chatToggle.getAttribute('aria-checked')==='true';
  if(on){ await stopRealtime(); setChatToggle(false); statusEl.textContent='CHAT OFF. Press-and-hold active.'; return; }
  await startRealtime(); setChatToggle(true); statusEl.textContent='CHAT mode: listening‚Ä¶';
}

async function startRealtime(){
  await primeAudio(); // unlock autoplay
  rtStream = await getMic();
  try{ rtRecorder = new MediaRecorder(rtStream,{ mimeType:supported }); } catch { rtRecorder = new MediaRecorder(rtStream); }

  // reset state for a new session
  rtQueue=[]; rtLiveText=''; lastChunkAt=0;

  // Each chunk is its own WebM; DO NOT concatenate.
  rtRecorder.ondataavailable = (ev)=>{
    if(ev.data && ev.data.size){
      rtQueue.push(ev.data);
      if(ev.data.size >= MIN_CHUNK_BYTES) lastChunkAt = Date.now(); // any meaningful chunk = user still speaking
      log(`[CHAT] chunk ${ev.data.size} bytes (queue=${rtQueue.length})`);
    }
  };
  rtRecorder.start(CHUNK_MS);
  log(`[CHAT] recorder started @ ${CHUNK_MS}ms (${supported})`);

  // timers
  rtSendTimer    = setInterval(sendPendingChunks, SEND_TICK_MS);
  rtSilenceTimer = setInterval(checkFinalizeTurn, 250);
}

async function stopRealtime(){
  try{ if(rtSendTimer) clearInterval(rtSendTimer); }catch{}
  try{ if(rtSilenceTimer) clearInterval(rtSilenceTimer); }catch{}
  rtSendTimer=null; rtSilenceTimer=null;

  try{ if(rtRecorder && rtRecorder.state!=='inactive') rtRecorder.stop(); }catch{}
  rtRecorder=null;

  try{ if(rtStream) rtStream.getTracks().forEach(t=>t.stop()); }catch{}
  rtStream=null;
}

async function sendPendingChunks(){
  if(!rtQueue.length) return;
  // gently drain the queue; never fuse files together
  const take = Math.min(rtQueue.length, 3);
  for(let i=0;i<take;i++){
    const blob = rtQueue.shift();
    if(!blob || !blob.size) continue;
    if(blob.size < MIN_CHUNK_BYTES){ log(`[CHAT] skip tiny ${blob.size}B`); continue; }

    try{
      const text = await callTranscribe(await blobToDataUrl(blob));
      if(text){
        rtLiveText = mergeTranscript(rtLiveText, text);
        output.textContent = `You (live): ${rtLiveText}`;
      }
    }catch(e){ log(`[CHAT] transcribe error: ${String(e)}`); }
  }
}

async function checkFinalizeTurn(){
  if(!rtLiveText) return;                   // nothing to send yet
  if(Date.now() - lastChunkAt < SILENCE_MS) return; // still speaking

  const toSend = rtLiveText;
  rtLiveText = '';                          // clear for next turn
  output.textContent = `You: ${toSend}\nThinking‚Ä¶`;

  try{
    const reply = await callChat(toSend);
    output.textContent = `You: ${toSend}\nAssistant: ${reply}`;
    await callSpeak(reply);
    // Do NOT stop recorder; keep listening for next sentence
    lastChunkAt = 0; // ensure new turn starts cleanly
  }catch(e){ log(`[CHAT] chat error: ${String(e)}`); output.textContent='Chat error.'; }
}

/* =============================================================================
   SECTION 7 ‚Äî SELF-TEST (optional): chat ‚Üí record once ‚Üí transcribe ‚Üí reply
   (Does NOT change app state; only used for diagnostics)
============================================================================= */
selfTestBtn.onclick = async ()=>{
  log('[SELFTEST] start');
  try{
    const hello = await callChat('Say ‚Äúhello‚Äù in five words.');
    log(`[SELFTEST] chat OK: ${hello}`);

    const stream = await getMic();
    let rec; try{ rec = new MediaRecorder(stream,{ mimeType:supported }); }catch{ rec = new MediaRecorder(stream); }
    const chunks=[];
    rec.ondataavailable = e=>{ if(e.data && e.data.size){ chunks.push(e.data); log(`[SELFTEST] chunk ${e.data.size}B`);} };
    rec.start(); log('[SELFTEST] recording ~3s‚Ä¶');
    await new Promise(r=>setTimeout(r,3000));
    try{ rec.requestData && rec.requestData(); }catch{}
    rec.stop(); await new Promise(r=>rec.onstop=r);
    stream.getTracks().forEach(t=>t.stop());

    const blob = chunks[chunks.length-1];
    if(!blob || !blob.size){ log('[SELFTEST] no audio captured'); return; }
    const heard = await callTranscribe(await blobToDataUrl(blob));
    log(`[SELFTEST] heard: ${heard||'(empty)'}`);

    if(heard){
      const ack = await callChat(`You heard: ${heard}. Reply with a short acknowledgement.`);
      log(`[SELFTEST] chat(replay) OK: ${ack}`);
      await callSpeak(ack);
    }
    log('[SELFTEST] done');
  }catch(e){ log(`[SELFTEST] error: ${String(e)}`); }
};
</script>
</body>
</html>
