<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Realtime WebRTC Debug</title>
  <style>
    body { font-family: system-ui, sans-serif; padding: 24px; }
    #voiceToggle { padding: 10px 16px; font-size: 16px; }
    #log { margin-top: 16px; white-space: pre-wrap; font-family: ui-monospace, SFMono-Regular, monospace; }
  </style>
</head>
<body>
  <button id="voiceToggle">Start</button>
  <audio id="assistantAudio" autoplay playsinline></audio>
  <div id="log"></div>

  <script type="module">
    const logEl = document.getElementById('log');
    const log = (...a)=>{ const s=a.map(x=>typeof x==='string'?x:JSON.stringify(x,null,2)).join(' ');
                          logEl.textContent += s + '\n'; console.log(...a); };

    let pc = null, mic = null;
    const btn = document.getElementById('voiceToggle');
    const audioEl = document.getElementById('assistantAudio');

    async function startRealtime(){
      try {
        // Permissions info (helpful on mobile)
        try {
          if ('permissions' in navigator && navigator.permissions?.query) {
            const p = await navigator.permissions.query({ name: 'microphone' });
            log('[PERM] microphone:', p.state);
          }
        } catch {}

        log('[RT] getUserMedia…');
        mic = await navigator.mediaDevices.getUserMedia({ audio: true });
        const micTrack = mic.getTracks()[0];
        log('[MIC] track state:', micTrack?.readyState || 'none');

        pc = new RTCPeerConnection();

        pc.oniceconnectionstatechange = ()=> log('ICE:', pc.iceConnectionState);
        pc.onconnectionstatechange   = ()=> log('PC:',  pc.connectionState);

        pc.ontrack = (e)=>{
          log('[RT] ontrack: remote stream received');
          audioEl.srcObject = e.streams[0];
          audioEl.play().catch(err=>log('[AUDIO] play() blocked:', err?.message||err));
        };

        // === Attach audio exactly once ===
        // This creates a sender for the mic and also requests remote audio back.
        pc.addTransceiver(micTrack, { direction: 'sendrecv' });

        // Optional data channel (for session settings)
        const dc = pc.createDataChannel('oai-events');
        dc.onopen = () => {
          log('[RT] data channel open; sending session update');
          try {
            dc.send(JSON.stringify({
              type: 'session.update',
              session: { voice: 'verse', instructions: 'You are Nyx. Keep replies brief.' }
            }));
          } catch (e) { log('[DC] send error:', e?.message||e); }
        };

        // Debug current PC state before offer
        log('Senders:', pc.getSenders().map(s => s.track?.kind || 'none'));
        log('Transceivers:', pc.getTransceivers().map(tx => ({ direction: tx.direction, mid: tx.mid })));

        // Create offer; legacy hint encourages a recv audio m-line too
        const offer = await pc.createOffer({ offerToReceiveAudio: 1 });
        await pc.setLocalDescription(offer);

        const sdpPreview = offer.sdp ? offer.sdp.slice(0, 500) : 'NO_SDP';
        log('[RT] SDP offer preview (first 500 chars):\n' + sdpPreview);
        if (!offer.sdp?.includes('m=audio')) {
          log('[ERR] SDP has no m=audio line — server will reject this.');
        }

        log('[RT] posting offer to /api/realtime/offer');
        const res = await fetch('/api/realtime/offer', {
          method: 'POST',
          headers: { 'Content-Type': 'application/sdp' },
          body: offer.sdp
        });

        const text = await res.text();
        log('[RT] offer->answer status:', res.status);

        if (!res.ok) {
          try { log('[ERR] OpenAI Realtime error:', JSON.stringify(JSON.parse(text), null, 2)); }
          catch { log('[ERR] OpenAI Realtime error text:', text.slice(0,300)); }
          throw new Error('Offer->Answer failed');
        }

        await pc.setRemoteDescription({ type: 'answer', sdp: text });
        log('[RT] remote description set; waiting for audio…');

      } catch (e) {
        log('[EXC] startRealtime error:', e?.message || e);
        throw e; // bubble to outer catch to run stopRealtime
      }
    }

    function stopRealtime(){
      try { pc?.getSenders().forEach(s => s.track?.stop()); pc?.close(); } catch {}
      pc = null;
      try { mic?.getTracks().forEach(t => t.stop()); } catch {}
      mic = null;
      audioEl.srcObject = null;
      log('[RT] stopped');
    }

    let live = false;
    btn.addEventListener('click', async ()=>{
      btn.disabled = true;
      try {
        if (!live) { btn.textContent = 'Connecting…'; await startRealtime(); live = true; btn.textContent = 'Stop'; }
        else { stopRealtime(); live = false; btn.textContent = 'Start'; }
      } catch {
        stopRealtime(); live = false; btn.textContent = 'Start';
      } finally { btn.disabled = false; }
    });
  </script>
</body>
</html>
